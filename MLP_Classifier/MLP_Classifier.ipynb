{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training Accuracy: 0.2605633802816901, Validation Accuracy: 0.25\n",
      "Epoch 1 - Training Accuracy: 0.2605633802816901, Validation Accuracy: 0.19444444444444442\n",
      "Epoch 2 - Training Accuracy: 0.2676056338028169, Validation Accuracy: 0.2222222222222222\n",
      "Epoch 3 - Training Accuracy: 0.28873239436619713, Validation Accuracy: 0.25\n",
      "Epoch 4 - Training Accuracy: 0.31690140845070425, Validation Accuracy: 0.2777777777777778\n",
      "Epoch 5 - Training Accuracy: 0.3661971830985915, Validation Accuracy: 0.3055555555555556\n",
      "Epoch 6 - Training Accuracy: 0.4225352112676056, Validation Accuracy: 0.4444444444444444\n",
      "Epoch 7 - Training Accuracy: 0.46478873239436624, Validation Accuracy: 0.4722222222222222\n",
      "Epoch 8 - Training Accuracy: 0.4577464788732394, Validation Accuracy: 0.4444444444444444\n",
      "Epoch 9 - Training Accuracy: 0.4577464788732394, Validation Accuracy: 0.4722222222222222\n",
      "Epoch 10 - Training Accuracy: 0.4577464788732394, Validation Accuracy: 0.4722222222222222\n",
      "Epoch 11 - Training Accuracy: 0.4577464788732394, Validation Accuracy: 0.4722222222222222\n",
      "Epoch 12 - Training Accuracy: 0.471830985915493, Validation Accuracy: 0.5277777777777778\n",
      "Epoch 13 - Training Accuracy: 0.49295774647887325, Validation Accuracy: 0.5555555555555556\n",
      "Epoch 14 - Training Accuracy: 0.528169014084507, Validation Accuracy: 0.5555555555555556\n",
      "Epoch 15 - Training Accuracy: 0.5845070422535211, Validation Accuracy: 0.5833333333333333\n",
      "Epoch 16 - Training Accuracy: 0.6126760563380282, Validation Accuracy: 0.6111111111111112\n",
      "Epoch 17 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.6111111111111112\n",
      "Epoch 18 - Training Accuracy: 0.6619718309859155, Validation Accuracy: 0.6666666666666667\n",
      "Epoch 19 - Training Accuracy: 0.6619718309859155, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 20 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 21 - Training Accuracy: 0.6830985915492958, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 22 - Training Accuracy: 0.6901408450704225, Validation Accuracy: 0.7222222222222222\n",
      "Epoch 23 - Training Accuracy: 0.6830985915492958, Validation Accuracy: 0.7222222222222222\n",
      "Epoch 24 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 25 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 26 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 27 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 28 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.6944444444444444\n",
      "Epoch 29 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.7222222222222222\n",
      "Epoch 30 - Training Accuracy: 0.6549295774647887, Validation Accuracy: 0.7222222222222222\n",
      "Epoch 31 - Training Accuracy: 0.6549295774647887, Validation Accuracy: 0.75\n",
      "Epoch 32 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 33 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.75\n",
      "Epoch 34 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.75\n",
      "Epoch 35 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.75\n",
      "Epoch 36 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.75\n",
      "Epoch 37 - Training Accuracy: 0.6267605633802817, Validation Accuracy: 0.75\n",
      "Epoch 38 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 39 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 40 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 41 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 42 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 43 - Training Accuracy: 0.6338028169014085, Validation Accuracy: 0.75\n",
      "Epoch 44 - Training Accuracy: 0.6408450704225352, Validation Accuracy: 0.75\n",
      "Epoch 45 - Training Accuracy: 0.6408450704225352, Validation Accuracy: 0.7777777777777778\n",
      "Epoch 46 - Training Accuracy: 0.6619718309859155, Validation Accuracy: 0.7777777777777778\n",
      "Epoch 47 - Training Accuracy: 0.6690140845070423, Validation Accuracy: 0.7777777777777778\n",
      "Epoch 48 - Training Accuracy: 0.6830985915492958, Validation Accuracy: 0.7777777777777778\n",
      "Epoch 49 - Training Accuracy: 0.6901408450704225, Validation Accuracy: 0.8055555555555556\n",
      "Epoch 50 - Training Accuracy: 0.6971830985915493, Validation Accuracy: 0.8333333333333334\n",
      "Epoch 51 - Training Accuracy: 0.704225352112676, Validation Accuracy: 0.8611111111111112\n",
      "Epoch 52 - Training Accuracy: 0.7183098591549295, Validation Accuracy: 0.8611111111111112\n",
      "Epoch 53 - Training Accuracy: 0.7464788732394366, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 54 - Training Accuracy: 0.7535211267605634, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 55 - Training Accuracy: 0.7746478873239436, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 56 - Training Accuracy: 0.7887323943661972, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 57 - Training Accuracy: 0.7887323943661972, Validation Accuracy: 0.8888888888888888\n",
      "Epoch 58 - Training Accuracy: 0.8028169014084507, Validation Accuracy: 0.8888888888888888\n",
      "Epoch 59 - Training Accuracy: 0.8028169014084507, Validation Accuracy: 0.9166666666666666\n",
      "Epoch 60 - Training Accuracy: 0.8028169014084507, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 61 - Training Accuracy: 0.8169014084507042, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 62 - Training Accuracy: 0.8309859154929577, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 63 - Training Accuracy: 0.8309859154929577, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 64 - Training Accuracy: 0.8309859154929577, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 65 - Training Accuracy: 0.8309859154929577, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 66 - Training Accuracy: 0.8380281690140845, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 67 - Training Accuracy: 0.8450704225352113, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 68 - Training Accuracy: 0.8450704225352113, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 69 - Training Accuracy: 0.8450704225352113, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 70 - Training Accuracy: 0.852112676056338, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 71 - Training Accuracy: 0.852112676056338, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 72 - Training Accuracy: 0.852112676056338, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 73 - Training Accuracy: 0.852112676056338, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 74 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 75 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 76 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 77 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 78 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 79 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 80 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 81 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 82 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 83 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 84 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 85 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 86 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 87 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 88 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 89 - Training Accuracy: 0.8591549295774648, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 90 - Training Accuracy: 0.8661971830985915, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 91 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 92 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 93 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 94 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 95 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 96 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 97 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 98 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 99 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 100 - Training Accuracy: 0.8732394366197183, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 101 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 102 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 103 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 104 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 105 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 106 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 107 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 108 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 109 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 110 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 111 - Training Accuracy: 0.8802816901408451, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 112 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 113 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 114 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 115 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 116 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 117 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 118 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 119 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 120 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 121 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9444444444444444\n",
      "Epoch 122 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 123 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 124 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 125 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 126 - Training Accuracy: 0.8873239436619719, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 127 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 128 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 129 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 130 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 131 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 132 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 133 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 134 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 135 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 136 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 137 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 138 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 139 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 140 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 141 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 142 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 143 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 144 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 145 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 146 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 147 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 148 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 149 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 150 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 151 - Training Accuracy: 0.8943661971830986, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 152 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 153 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 154 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 155 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 156 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 157 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 158 - Training Accuracy: 0.9084507042253521, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 159 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 160 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 161 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 162 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 163 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 164 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 165 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 166 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 167 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 168 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 169 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 170 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 171 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 172 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 173 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 174 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 175 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 176 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 177 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 178 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 179 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 180 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 181 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 182 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 183 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 184 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 185 - Training Accuracy: 0.9014084507042254, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 186 - Training Accuracy: 0.9084507042253521, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 187 - Training Accuracy: 0.9084507042253521, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 188 - Training Accuracy: 0.9154929577464789, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 189 - Training Accuracy: 0.9154929577464789, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 190 - Training Accuracy: 0.9154929577464789, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 191 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 192 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 193 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 194 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 195 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 196 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 197 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 198 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 199 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 200 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 201 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 202 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 203 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 204 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 205 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 206 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 207 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 208 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 209 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 210 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 211 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 212 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 213 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 214 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 215 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 216 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 217 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 218 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 219 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 220 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 221 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 222 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 223 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 224 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 225 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 226 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 227 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 228 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 229 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 230 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 231 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 232 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 233 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 234 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 235 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 236 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 237 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 238 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 239 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 240 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 241 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 242 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 243 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 244 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 245 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 246 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 247 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 248 - Training Accuracy: 0.9647887323943662, Validation Accuracy: 1.0\n",
      "Epoch 249 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 1.0\n",
      "Epoch 250 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 1.0\n",
      "Epoch 251 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 1.0\n",
      "Epoch 252 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 1.0\n",
      "Epoch 253 - Training Accuracy: 0.9577464788732395, Validation Accuracy: 1.0\n",
      "Epoch 254 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 255 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 256 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 257 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 258 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 259 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 260 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 261 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 262 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 263 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 264 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 265 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 266 - Training Accuracy: 0.9507042253521126, Validation Accuracy: 1.0\n",
      "Epoch 267 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 268 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 269 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 270 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 271 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 272 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 273 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 274 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 275 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 276 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 277 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 278 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 279 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 0.9722222222222222\n",
      "Epoch 280 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 281 - Training Accuracy: 0.9436619718309859, Validation Accuracy: 1.0\n",
      "Epoch 282 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 1.0\n",
      "Epoch 283 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 1.0\n",
      "Epoch 284 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 1.0\n",
      "Epoch 285 - Training Accuracy: 0.9366197183098591, Validation Accuracy: 1.0\n",
      "Epoch 286 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 1.0\n",
      "Epoch 287 - Training Accuracy: 0.9295774647887324, Validation Accuracy: 1.0\n",
      "Epoch 288 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 289 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 290 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 291 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 292 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 293 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 294 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 295 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 296 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 297 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 298 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "Epoch 299 - Training Accuracy: 0.9225352112676056, Validation Accuracy: 1.0\n",
      "[3.] [0. 0. 1.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[3.] [0. 0. 1.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[3.] [0. 0. 1.]\n",
      "[2.] [0. 1. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[3.] [0. 0. 1.]\n",
      "[3.] [0. 0. 1.]\n",
      "[1.] [1. 0. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[3.] [0. 0. 1.]\n",
      "[3.] [0. 0. 1.]\n",
      "[2.] [0. 1. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[2.] [0. 1. 0.]\n",
      "[1.] [1. 0. 0.]\n",
      "[3.] [0. 0. 1.]\n",
      "[1.] [1. 0. 0.]\n",
      "[1.] [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# DATA PREPROCESSING\n",
    "#------------------------------------------------------------------------\n",
    "def load_data(datapath):\n",
    "    csv_path = os.path.abspath(datapath)\n",
    "    return pd.read_csv(csv_path, header=None)\n",
    "\n",
    "def data_split(dataset):\n",
    "    #shuffling dataset\n",
    "    dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    #splitting train/test\n",
    "    train = dataset.sample(frac=0.8)\n",
    "    val = dataset.drop(train.index)\n",
    "\n",
    "    #splitting attributes/labels\n",
    "    train_y = train.iloc[:,0]\n",
    "    train_x = train.drop(0, axis=1)\n",
    "    val_y = val.iloc[:,0]\n",
    "    val_x = val.drop(0, axis=1)\n",
    "    return train_x, train_y, val_x, val_y\n",
    "\n",
    "def standardize(df):\n",
    "    df_stand = df.copy()\n",
    "    for column in df_stand.columns:\n",
    "        df_stand[column] = (df_stand[column] - df_stand[column].mean()) / df_stand[column].std()    \n",
    "    return df_stand\n",
    "\n",
    "def onehotencode(series):\n",
    "    vector = np.array(series)\n",
    "    encoded = np.zeros(shape=(len(vector),3))\n",
    "    for i in range(len(vector)):\n",
    "        if vector[i] == 1:\n",
    "            encoded[i] = np.array([1,0,0])\n",
    "        if vector[i] == 2:\n",
    "            encoded[i] = np.array([0,1,0])\n",
    "        if vector[i] == 3:\n",
    "            encoded[i] = np.array([0,0,1])\n",
    "    return encoded\n",
    "\n",
    "#---------------------------------------------------------------------------------------\n",
    "# MLP\n",
    "#---------------------------------------------------------------------------------------\n",
    "\n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, n_hidden, n_input_feat, n_classes, learning_rate, epochs):\n",
    "        self.n_hidden = n_hidden #4\n",
    "        self.n_input = n_input_feat #13\n",
    "        self.n_output = n_classes #3\n",
    "        self.lr = learning_rate #0.01\n",
    "        self.epochs = epochs #40\n",
    "\n",
    "        self.v = np.random.uniform(size=((self.n_input+1)*self.n_hidden,1))\n",
    "        self.w = np.random.uniform(size=((self.n_hidden+1)*self.n_output,1))\n",
    "\n",
    "\n",
    "    def hidden_layer(self, x, v):\n",
    "        a = np.zeros(shape=(self.n_hidden,1))\n",
    "        for node in range(self.n_hidden): #0,1,2,3\n",
    "            a_x = np.zeros(shape=(self.n_input+1,1)) \n",
    "            for index in range(len(v)): #0,1,2,3,...,54,55\n",
    "                if index % self.n_hidden == node:\n",
    "                    a_x[index//self.n_hidden] = v[index]\n",
    "            a[node] = np.dot(a_x.T,x)\n",
    "        return a\n",
    "        \n",
    "    def sigmoid(self, vector):\n",
    "        for entry in range(len(vector)):\n",
    "            vector[entry] = (lambda z: 1/(1 + np.exp(-z)))(vector[entry])\n",
    "        return vector\n",
    "    \n",
    "    def output_layer(self, a, w):\n",
    "        y = np.zeros(shape=(self.n_output,1))\n",
    "        for node in range(self.n_output): #0,1,2\n",
    "            y_a = np.zeros(shape=(self.n_hidden+1,1)) \n",
    "            for index in range(len(w)): #0,1,2,3,...,14\n",
    "                if index % self.n_output == node:\n",
    "                    y_a[index//self.n_output] = w[index]\n",
    "            y[node] = np.dot(y_a.T,a)\n",
    "        return y\n",
    "        \n",
    "    def softmax(self, vector):\n",
    "        e_vector = np.exp(vector)\n",
    "        sum = np.sum(e_vector)\n",
    "        return e_vector*(1/sum)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = np.array(input).reshape(self.n_input,1)\n",
    "        x = np.append(np.array([[1]]), input, axis=0)\n",
    "        a = self.sigmoid(self.hidden_layer(x, self.v))\n",
    "        a = np.array(a).reshape(self.n_hidden,1)\n",
    "        a = np.append(np.array([[1]]), a, axis=0)\n",
    "        a1 = np.ndarray.copy(a)\n",
    "        y = self.softmax(self.output_layer(a1, self.w))\n",
    "        return (x,a,y)\n",
    "     \n",
    "    def delta_output(self, prediction, label):\n",
    "        return (prediction-label)*prediction*(1-prediction)\n",
    "    \n",
    "    def delta_hidden(self, a, delt_out):\n",
    "        delt_hidd = np.zeros(shape=np.shape(a))\n",
    "        for j in range(len(delt_hidd)):\n",
    "            loc_sum = 0\n",
    "            for index in range(len(self.w)):\n",
    "                which_a = index // self.n_output\n",
    "                which_out_node = index % self.n_output\n",
    "                if which_a == j:\n",
    "                    loc_sum += delt_out[which_out_node]*self.w[index]\n",
    "            delt_hidd[j] = a[j]*(1-a[j])*loc_sum\n",
    "        return delt_hidd\n",
    "\n",
    "    def predict(self, attributes):\n",
    "        prediction = np.zeros(shape=(len(attributes.index),1))\n",
    "        for i in range(len(attributes.index)):\n",
    "            x, a, y = self.forward(attributes.iloc[i])\n",
    "            for j in range(len(y)):\n",
    "                if y[j] == np.amax(y):\n",
    "                    prediction[i] = j+1\n",
    "        return prediction\n",
    "\n",
    "\n",
    "    def fit(self, train_attrib, train_labels, val_attrib, val_labels):\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            train_missed, val_missed = 0., 0.\n",
    "\n",
    "            for i in range(len(train_attrib)):\n",
    "\n",
    "                tr_label =  np.array(train_labels[i]).reshape(self.n_output,1)\n",
    "\n",
    "                #forward pass for training data\n",
    "                x, a, y  = self.forward(train_attrib.iloc[i])\n",
    "\n",
    "                #updating error term\n",
    "                tr_pred_one_hot = np.zeros(shape=np.shape(y))\n",
    "                for i in range(len(y)):\n",
    "                    if y[i] == np.amax(y):\n",
    "                        tr_pred_one_hot[i] = 1\n",
    "                if not np.array_equal(tr_pred_one_hot, tr_label):\n",
    "                    train_missed += 1\n",
    "\n",
    "                #calculating gradients\n",
    "                delt_out = self.delta_output(y,tr_label) #tensor of shape len(self.n_output)\n",
    "                delt_hidd = self.delta_hidden(a, delt_out) #tensor of shape len(self.n_hidden)\n",
    "\n",
    "                #calculating second layer weights updates\n",
    "                new_w = np.zeros(shape=np.shape(self.w))\n",
    "                for index in range(len(self.w)):\n",
    "                    which_a = index // self.n_output\n",
    "                    which_out_node = index % self.n_output\n",
    "                    new_w[index] = self.w[index] - self.lr*delt_out[which_out_node]*a[which_a]\n",
    "                \n",
    "                #calculating first layer weights updates\n",
    "                new_v = np.zeros(shape=np.shape(self.v))\n",
    "                for index in range(len(self.v)):\n",
    "                    which_in_node = index // self.n_hidden\n",
    "                    which_hidd_node = index % self.n_hidden\n",
    "                    new_v[index] = self.v[index] - self.lr*delt_hidd[which_hidd_node]*x[which_in_node]\n",
    "\n",
    "                #updating weights   \n",
    "                self.w = new_w\n",
    "                self.v = new_v\n",
    "            \n",
    "            #forward pass for validation set\n",
    "            for j in range(len(val_attrib)):\n",
    "                val_label =  np.array(val_labels[j]).reshape(self.n_output,1)\n",
    "                val_x, val_a, val_y  = self.forward(val_attrib.iloc[j])\n",
    "\n",
    "            #updating error term for validation set\n",
    "                val_pred_one_hot = np.zeros(shape=np.shape(val_y))\n",
    "                for i in range(len(val_y)):\n",
    "                    if val_y[i] == np.amax(val_y):\n",
    "                        val_pred_one_hot[i] = 1\n",
    "                if not np.array_equal(val_pred_one_hot, val_label):\n",
    "                    val_missed += 1\n",
    "\n",
    "            #calculating accuracy  \n",
    "            train_acc = 1 - train_missed/len(train_attrib)\n",
    "            val_acc = 1 - val_missed/len(val_attrib)\n",
    "\n",
    "            print(f'Epoch {epoch} - Training Accuracy: {train_acc}, Validation Accuracy: {val_acc}')\n",
    "            pass\n",
    "\n",
    "\n",
    "def main(datapath):\n",
    "    #splitting dataset\n",
    "    train_x, train_y, val_x, val_y = data_split(load_data(datapath))\n",
    "\n",
    "    #standardizing attributes\n",
    "    train_x_stand, val_x_stand = standardize(train_x), standardize(val_x)\n",
    "\n",
    "    #one-hot-encoding labels\n",
    "    train_y_hot = onehotencode(train_y)\n",
    "    val_y_hot = onehotencode(val_y)\n",
    "\n",
    "    #training my MLP\n",
    "    myMLP = MLP(4,13,3,0.01,300)\n",
    "    myMLP.fit(train_x_stand, train_y_hot, val_x_stand, val_y_hot)\n",
    "    # prediction = myMLP.predict(val_x_stand)\n",
    "    # for i, j in zip(prediction, val_y_hot):\n",
    "    #     print(i,j)\n",
    "    pass\n",
    "\n",
    "\n",
    "main('wine.data')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References: \n",
    "\n",
    "[1] Slides from Haixu Tang: https://iu.instructure.com/courses/2117762/pages/module-5-multi-layer-perceptron-mlp?module_item_id=28540669\n",
    "\n",
    "[2] NumPy User Guide: https://numpy.org/doc/stable/user/\n",
    "\n",
    "[3] pandas User Guide: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "\n",
    "[4] matplotlib User Guide: https://matplotlib.org/stable/users/index.html\n",
    "\n",
    "[5] MXNet's Python Tutorial for training a neural netowrk: https://mxnet.apache.org/versions/1.7/api/python/docs/tutorials/getting-started/crash-course/4-train.html\n",
    "\n",
    "[6] Vitor Gama Lemos - \"Multilayer Perceptron from scratch\": https://www.kaggle.com/code/vitorgamalemos/multilayer-perceptron-from-scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3056e99c9ab1ba1a35baf3512c9c98f5b428e9ef304492238fb3afedd59f1d06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
